{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711185d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load test_multi_with_label.py\n",
    "#usage:python3 test_multi.py testpath\n",
    "#对testpath目录下的若干个样本进行测试，将测试结果输出到csv中。\n",
    "\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Concatenate, Dropout, Masking, Bidirectional, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from gensim.models import word2vec\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential,Model\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from utils import *\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import json\n",
    "import csv\n",
    "import heapq\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 800\n",
    "EMBEDDING_DIM = 30\n",
    "\n",
    "path = \"sard_10_classes/\"\n",
    "testpath = sys.argv[1]\n",
    "modelpath = \"models/\"\n",
    "\n",
    "#不输出warning信息\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#禁用gpu，强制使用cpu（因为nvidia驱动版本太老，尚未更新，临时设置此项）\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "class Attention(Layer):\n",
    "\tdef __init__(self,step_dim=MAX_SEQUENCE_LENGTH,\n",
    "\t\t\t\t W_regularizer=None, b_regularizer=None,\n",
    "\t\t\t\t W_constraint=None, b_constraint=None,\n",
    "\t\t\t\t bias=True, **kwargs):\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.init = initializers.get('glorot_uniform')\n",
    "\n",
    "\t\tself.W_regularizer = regularizers.get(W_regularizer)\n",
    "\t\tself.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "\t\tself.W_constraint = constraints.get(W_constraint)\n",
    "\t\tself.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "\t\tself.bias = bias\n",
    "\t\tself.step_dim = step_dim\n",
    "\t\tself.features_dim = 0\n",
    "\t\tsuper(Attention, self).__init__(**kwargs)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tassert len(input_shape) == 3\n",
    "\n",
    "\t\tself.W = self.add_weight(shape=(input_shape[-1],),\n",
    "\t\t\t\t\t\t\t\t initializer=self.init,\n",
    "\t\t\t\t\t\t\t\t name='{}_W'.format(self.name),\n",
    "\t\t\t\t\t\t\t\t regularizer=self.W_regularizer,\n",
    "\t\t\t\t\t\t\t\t constraint=self.W_constraint)\n",
    "\t\tself.features_dim = input_shape[-1]\n",
    "\n",
    "\t\tif self.bias:\n",
    "\t\t\tself.b = self.add_weight(shape=(input_shape[1],),\n",
    "\t\t\t\t\t\t\t\t\t initializer='zero',\n",
    "\t\t\t\t\t\t\t\t\t name='{}_b'.format(self.name),\n",
    "\t\t\t\t\t\t\t\t\t regularizer=self.b_regularizer,\n",
    "\t\t\t\t\t\t\t\t\t constraint=self.b_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.b = None\n",
    "\n",
    "\t\tself.built = True\n",
    "\n",
    "\tdef compute_mask(self, input, input_mask=None):\n",
    "\t\treturn None\n",
    "\n",
    "\tdef call(self, x, mask=None):\n",
    "\t\tfeatures_dim = self.features_dim\n",
    "\t\tstep_dim = self.step_dim\n",
    "\n",
    "\t\teij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "\t\t\t\t\t\tK.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "\t\tif self.bias:\n",
    "\t\t\teij += self.b\n",
    "\n",
    "\t\teij = K.tanh(eij)\n",
    "\n",
    "\t\ta = K.exp(eij)\n",
    "\n",
    "\t\tif mask is not None:\n",
    "\t\t\ta *= K.cast(mask, K.floatx())\n",
    "\n",
    "\t\ta /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "\t\ta = K.expand_dims(a)\n",
    "\t\tweighted_input = x * a\n",
    "\t\treturn K.sum(weighted_input, axis=1)\n",
    "\n",
    "\tdef compute_output_shape(self, input_shape):\n",
    "\t\treturn input_shape[0],  self.features_dim\n",
    "\n",
    "if not os.path.isfile('word_index.json'):\n",
    "\tprint('word_index.json does not exist.')\n",
    "\texit()\n",
    "else:\n",
    "\tword_index = read_data_from_json('word_index.json')\n",
    "nb_words = len(word_index)+1\n",
    "\n",
    "\n",
    "if not os.path.isfile('test_compare_sample.json'):\n",
    "\tif not os.path.isfile('pad_sequence.json'):\n",
    "\t\tprint('pad_sequence.json does not exist.')\n",
    "\t\texit()\n",
    "\telse:\n",
    "\t\tpad_sequence = read_data_from_json('pad_sequence.json')\n",
    "\n",
    "\tif not os.path.isfile('pad_label.json'):\n",
    "\t\tprint('pad_label.json does not exist.')\n",
    "\t\texit()\n",
    "\telse:\n",
    "\t\tpad_label = read_data_from_json('pad_label.json')\n",
    "\n",
    "\t#now we have pad_sequence and pad_label\n",
    "\n",
    "\ttest_compare_sample = create_test_compare_sample(pad_sequence,pad_label)\n",
    "\twrite_data_to_json(test_compare_sample,'test_compare_sample.json')\n",
    "else:\n",
    "\ttest_compare_sample = read_data_from_json('test_compare_sample.json')\n",
    "\n",
    "\n",
    "target_pad_sequences = []\n",
    "target_pad_labels = []\n",
    "test_file_names = []\n",
    "\n",
    "#对testpath中的切片做变量名替换，并将文件夹名字加上后缀_transferred。\n",
    "if testpath[-1] != '/':\n",
    "\tprint(\"error:testpath format should be xxxx/\")\n",
    "\texit()\n",
    "elif os.path.isdir(testpath[:-1]+\"_transferred/\"):\n",
    "\tprint(\"已经做过变量名替换。\")\n",
    "\ttestpath = testpath[:-1]+\"_transferred/\"\n",
    "else:\n",
    "\tvar_fun_transfer_folder(testpath,testpath[:-1]+\"_transferred/\")\n",
    "\ttestpath = testpath[:-1]+\"_transferred/\"\n",
    "\n",
    "\n",
    "for root, _, files in os.walk(testpath):\n",
    "\tfor name in files:\n",
    "\t\ttarget_pad_sequences.append(test_target_preprocess(os.path.join(root, name),word_index,MAX_SEQUENCE_LENGTH))\n",
    "\t\ttarget_pad_labels.append(get_label(name))\n",
    "\t\ttest_file_names.append(name)\n",
    "\n",
    "print('Total number of target_pad_sequences :',len(target_pad_sequences))\n",
    "\n",
    "\n",
    "#total_score是一个二维数组，外层表示对应的类别，内层表示每个样本对应该类别的可能性评分（0-1之间）。\n",
    "total_score = []\n",
    "for kind in range(1,11):\n",
    "\tprint('Loading model:',str(kind)+'_bilstm_model.h5')\n",
    "\tmodel = load_model(modelpath+str(kind)+'_bilstm_model.h5',custom_objects={\"Attention\": Attention})\n",
    "\tpairs_1 = []\n",
    "\tpairs_2 = []\n",
    "\tfor i in range(len(target_pad_sequences)):\n",
    "\t\tfor j in range((kind-1)*5,kind*5):\n",
    "\t\t\tpairs_1.append(target_pad_sequences[i])\n",
    "\t\t\tpairs_2.append(test_compare_sample[j])\n",
    "\tprint('Start predicting with model:',str(kind)+'_bilstm_model.h5')\n",
    "\tscore_list_1 = model.predict([pairs_1,pairs_2], batch_size=100, verbose=0)\n",
    "\tscore_list_1 = score_list_1.reshape(-1)\n",
    "\tprint('Predicting with model:',str(kind)+'_bilstm_model.h5',' finished.')\n",
    "\tscore_list_2 = []\n",
    "\tfor i in range(len(target_pad_sequences)):\n",
    "\t\t#保留五位小数\n",
    "\t\tscore_list_2.append(round(sum(score_list_1[i*5:(i+1)*5])/5.0,5))\n",
    "\tprint('kind ',kind,'results finished. Next model.')\n",
    "\ttotal_score.append(score_list_2)\n",
    "\n",
    "\n",
    "number_of_samples = len(target_pad_sequences)\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "f = open('results.csv','w',encoding='utf-8',newline='')\n",
    "csv_writer = csv.writer(f)\n",
    "csv_writer.writerow([\"filename\",\"result_top1\",\"result_top2\",\"result_top3\",\"score1\",\"score2\",\"score3\",\"score4\",\"score5\",\"score6\",\"score7\",\"score8\",\"score9\",\"score10\"])\n",
    "\n",
    "for i in range(len(target_pad_sequences)):\n",
    "\tone_sample_score = []\n",
    "\tfor j in range(len(total_score)):\n",
    "\t\tone_sample_score.append(total_score[j][i])\n",
    "\tone_sample_top3_score = heapq.nlargest(3, one_sample_score)\n",
    "\tone_sample_top3_index = list(map(one_sample_score.index, heapq.nlargest(3, one_sample_score)))\n",
    "\tif one_sample_top3_score[0] > 0.5:\n",
    "\t\tone_sample_result = [one_sample_top3_index[0]+1,one_sample_top3_index[1]+1,one_sample_top3_index[2]+1]\n",
    "\telse:\n",
    "\t\tone_sample_result = [0,0,0]\n",
    "\tcsv_writer.writerow([test_file_names[i],one_sample_result[0],one_sample_result[1],one_sample_result[2]]+one_sample_score)\n",
    "\n",
    "\tif one_sample_result == [0,0,0] and target_pad_labels[i] == 0:\n",
    "\t\tTN += 1\n",
    "\telif one_sample_result != [0,0,0] and target_pad_labels[i] in one_sample_result:\n",
    "\t\tTP += 1\n",
    "\telif one_sample_result == [0,0,0] and target_pad_labels[i] != 0:\n",
    "\t\tFN += 1\n",
    "\telse:\n",
    "\t\tFP += 1\n",
    "\n",
    "print('Write csv finished.')\n",
    "f.close()\n",
    "\n",
    "#准确率\n",
    "accuracy = (TP+TN)/(number_of_samples)\n",
    "#检出率\n",
    "recall = TP/(TP+FN)\n",
    "#误报率\n",
    "false_positive_rate = FP/(FP+TP)\n",
    "#打印结果\n",
    "print('===================测试结果===================')\n",
    "print('测试结果已写入文件：results.csv')\n",
    "print('TP=',TP,' TN=',TN,' FP=',FP,' FN=',FN)\n",
    "print('检出率：',recall)\n",
    "print('误报率：',false_positive_rate)\n",
    "print('准确率：',accuracy)\n",
    "print('==============================================')\n",
    "os.system('rm -rf ' + testpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
